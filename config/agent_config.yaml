# Agent Configuration
# Controls the behavior of the Ollama-powered agent

agent:
  # Default model to use (can be changed via /model command)
  # Set to null to auto-select first available model
  # Recommended models (in order of preference):
  #   1. qwen2.5:3b or qwen2.5:7b - Best balance of size/capability
  #   2. llama3.2:3b - Good instruction following
  #   3. mistral:7b - Reliable but larger
  #   4. qwen2:0.5b - Smallest, fastest, but less capable
  #
  # AVOID reasoning models like deepseek-r1 - they output thinking process
  # which causes hallucinations in the agent loop
  default_model: null  # Auto-select from available models

  # Available models are auto-discovered from Ollama on startup
  # No need to configure here - they're fetched dynamically

  # Agent mode enabled by default (can be toggled via /agent command)
  enabled: true

  # Enable verbose mode (shows reasoning steps)
  verbose: true

  # Maximum number of reasoning steps before stopping
  max_steps: 10

  # Token management
  tokens:
    # Maximum tokens for context window
    max_context_tokens: 4096
    # Reserve tokens for agent response
    response_reserve: 1024
    # Truncate strategy: "oldest" or "summarize"
    truncate_strategy: "oldest"

# Ollama connection settings
ollama:
  # Ollama API endpoint
  base_url: "http://localhost:11434"

  # Request timeout (seconds)
  timeout: 120

  # Enable streaming responses
  stream: true

  # Temperature for generation (0.0 = deterministic, 1.0 = creative)
  temperature: 0.7

  # Top-p sampling
  top_p: 0.9

  # Number of tokens to predict (-1 = infinite)
  num_predict: -1

# Agentic loop configuration
loop:
  # Phases: think -> plan -> act -> observe -> reflect
  # NOTE: Think phase disabled by default to prevent hallucinations with small models
  phases:
    think:
      enabled: false  # Disabled - causes hallucinations with reasoning models
      prompt_template: "system_think"

    plan:
      enabled: false  # Simplified - tool selection happens in Act phase
      prompt_template: "system_plan"
      max_plan_steps: 5

    act:
      enabled: true
      prompt_template: "system_act"
      # Direct tool execution without separate planning
      direct_mode: true
      # Execute tools in parallel when possible
      parallel_execution: false

    observe:
      enabled: true
      # Parse tool results and errors
      parse_errors: true

    reflect:
      enabled: false  # Disabled for simpler operation
      # Learn from errors
      error_learning: true

# Error recovery settings
error_recovery:
  # Enable automatic retry
  enabled: true

  # Maximum retries per operation
  max_retries: 3

  # Retry strategies by error type
  strategies:
    permission_denied:
      action: "request_approval"
      auto_retry: true

    file_not_found:
      action: "search_alternatives"
      auto_retry: true

    syntax_error:
      action: "fix_and_retry"
      auto_retry: true

    network_error:
      action: "exponential_backoff"
      auto_retry: true
      backoff_base: 2
      backoff_max: 30

    timeout:
      action: "increase_timeout"
      auto_retry: true
      timeout_multiplier: 1.5

  # Default action for unknown errors
  default_action: "report_and_ask"

# Learning and memory
memory:
  # Enable conversation history
  enabled: true

  # Maximum messages to keep in memory
  max_messages: 100

  # Persist to file
  persist:
    enabled: true
    directory: "~/.claude-agent/history"
    format: "json"

  # Enable session summarization
  summarize:
    enabled: true
    threshold_messages: 50
    keep_recent: 10

# Safety and guardrails
safety:
  # Require confirmation for destructive operations
  confirm_destructive: true

  # List of destructive patterns
  destructive_patterns:
    - "rm -rf"
    - "dd if="
    - "mkfs"
    - "> /dev/"
    - "format"
    - "DROP DATABASE"
    - "DELETE FROM .* WHERE"

  # Enable input validation
  validate_inputs: true

  # Enable output sanitization
  sanitize_outputs: true

  # Maximum file size to read (MB)
  max_file_size_mb: 10

  # Maximum files to process in batch
  max_batch_size: 50

# UI preferences
ui:
  # Show agent thinking process
  show_thinking: true

  # Show tool execution details
  show_tool_execution: true

  # Color scheme: "auto", "dark", "light"
  color_scheme: "auto"

  # Enable syntax highlighting
  syntax_highlighting: true

  # Markdown rendering
  markdown:
    enabled: true
    # Code theme for syntax highlighting
    code_theme: "monokai"
